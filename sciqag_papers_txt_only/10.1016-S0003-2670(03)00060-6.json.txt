In the pharmaceutical industry the early identification of toxicological side-effects of potential new drug candidates is of fundamental value in the minimisation of compound “attrition” . While specific assays have been developed to detect abnormal changes in biofluids of test animals, histopathological tissue examination remains the ‘gold-standard’ in toxicological assessment. Since investigating toxicity by traditional techniques is time consuming and costly, different approaches to the reliable and effective prediction of toxicity have been explored. Currently, there are several advanced technologies using multiparametric biochemical information derived from different levels of biomolecular organisation. Genomic and proteomic information describing transcriptional effects and protein synthesis can be extracted . However, these approaches are also slow and expensive. Alternatively, the metabonomic approach analyses the entire pool of endogenous metabolites in a biofluid or tissue, and is a powerful technique for detecting and describing biological endpoint-effects. It has already proven to be effective in the description of genetic strain differences, disease states, nutritional effects and toxic influences . In this study, we report the initial evaluation of metabonomic data yielded in a large-scale toxicological project within the COnsortium for MEtabonomic Toxicology (COMET). The COMET 1 project is currently constructing databases and metabolic models of drug toxicity using ca. 100,000 1H NMR spectra of biofluids from rats and mice treated with approximately 150 model compounds. Multivariate statistical models characterising the effects of toxins on endogenous metabolite profiles have been generated and will be used for the development of computer-based expert systems. These will enable rapid pre-clinical toxicological screening of potential drug candidates.
As a prototype for such large and comprehensive databases we have used a subset of the data to study dose- and time-related effects, to develop and evaluate classification methods and explore characteristic features of toxicity (the ‘biomarker profile’). This facilitates the prediction and interpretation of large-scale data sets and will help to hone the development of new analytical tools. We describe a first attempt to explore and predict the effect of different toxins, surgical procedures and other external influences in 19 independent studies using 1H NMR-metabonomic analysis of rat urine samples. Urine samples were collected from dosed and control rats at 10 time points over a period of 8 days and were subsequently analysed by 600 MHz 1H NMR spectroscopy. Principal component analysis (PCA) and hierarchical cluster analysis (HCA) were applied to the data from the studies to reveal dose and time-related effects in the response of animals to different toxins. Finally, k-nearest-neighbour (kNN) classification was used to predict how well individual samples were classified into their respective class and time point. This work gives an insight into the scope of this project and illustrates the diagnostic power and reliability of metabonomic data analysis using 1H NMR spectroscopy together with chemometric techniques for the exploration and prediction of toxic effects.
In established in-house or external animal research facilities of the involved pharmaceutical companies, male 8–10 week old Sprague-Dawley rats were housed in metabolism cages and urine samples collected daily. Free access to food and water was permitted throughout the studies (except in the case of food and water restriction studies). The animals were randomly assigned to three dose groups: control (vehicle only, n=10), high-dose (dose causing a clear toxic effect, n=10) and low-dose (sub-toxic dose, n=10). For those studies without drug-treatment, classes were distinguished as follows: partial hepatectomy (L9), unilateral nephrectomy (K5), food restriction (O5): (1) 25%, (2) 50%, (3) 100% (for 1 day); 48 h water deprivation (O4).
In general, the animals were dosed or underwent surgery at 0 h. Urine samples were collected at −16 h (predose) (n=10) and 0 h (n=10), 8 h (n=10), 24 h (n=10), 48 h (n=10), 72 h (n=5), 96 h (n=5), 120 h (n=5), 144 h (n=5) and 168 h (n=5) postdose (p.d.) and stored at −40 °C. Half of the animals was euthanised at 48 h p.d., the other half at 168 h p.d. and organ tissue samples (liver (L), kidney (K) and in a small number of cases the pancreas) were submitted for histopathological examination (Table 1 ).
1H NMR spectroscopy was carried out using an AVANCE 600 MHz spectrometer (Bruker Analytische GmbH, Faellanden, Switzerland). Aliquots of each urine sample (400 μl) were added to 200 μl of sodium phosphate buffer (0.2 M Na2HPO4 in H2O and 0.2 M NaH2PO4 in 80:20 H2O:D2O, pH 7.4) containing 1 mM sodium trimethylsilyl [2,2,3,3-2H4] propionate (TSP) and 3 mM sodium azide. Samples were centrifuged at ∼1800 × g for 5 min to remove any solid debris. 1H NMR spectra were measured at 300 K using a flow-injection system (Bruker Biospin, Karlsruhe, Germany). NMR acquisition was performed using the first increment of a NOESY sequence with irradiation of the water frequence during the mixing time and relaxation delay. This resulted in a total acquisition time of ∼4 min per sample.
Spectra were automatically phase- and baseline-corrected and referenced to the chemical shift of TSP (δ = 0.0) using a Matlab routine (The MathWorks, Natick, Massachusetts) written in-house. Each NMR spectrum was reduced to 205 integrated regions of equal width (0.04 ppm) corresponding to the region δ = 0.2–10.0, excluding the region surrounding the water signal from δ = 4.50–5.98. All spectra were normalised to a constant integrated intensity of 100 units.
Excretion of drug-related compounds into the urine can contribute to additional large signals in the 1H NMR spectra. These distort the scaling of spectra and give false classification results (as they are compound-related, not endogenous and show clear time- and dose-related concentration changes). In order to minimize the effect of drug-related signals in our study set of NMR spectra, the affected areas were treated according to a standard procedure as detailed in .
Metabonomic changes in the urine samples were seen in the high-dose experiments and in some of the low-dose studies. For this first evaluation, only high-dose samples, where toxicity was confirmed by histopathology, and control samples (including predose samples) were compared.
Four classification tasks were undertaken using the metabonomic sample data:
Classification of samples according to organ-site specificity (liver, kidney or controls (C)).
Prediction of organ-site specificity for a four-class system (liver, kidney, a further group comprising other (O) effects, or controls).
Prediction of all samples into the individual studies.
Prediction of the samples into their individual time points.
For most of the toxicological studies time points could be identified where the metabonomic urine profile changes significantly compared to controls. In order to classify the different studies, the selection of time points is vital. Studies can be either compared at the time point of maximum effect or at all time points showing an effect distinct from the control samples (Fig. 1 ). Both ways of characterising the study-specific differences were applied. In many of the studies a maximum effect could be observed at 48 h postdose (Table 1). Therefore, one particular comparison was carried out using the 48 h samples only.
Principal component analysis and partial-least-squares discriminant analysis (PLS-DA) were used in order to visualise the complex multivariate dataspace. Scores plots facilitated visualisation of the study-specific clustering of samples, while loadings plots revealed the characteristic underlying metabolic changes by showing the influence of the different spectral areas on the principal components (PCs). PCA and PLS-DA were performed using SIMCA-P 9.0 (Umetrics AB, Umeå, Sweden).
HCA was applied to the data in order to detect intra- and inter-study similarities. In the individual studies, the spectral data at each time point significantly different from controls were averaged across animals and used for subsequent analysis. Centroidal linkage was chosen as the optimum linkage method, because it is less susceptible to effects of outliers and reduces problems due to overlap of clusters. HCA was performed using Pirouette 2.70 (Infometrix Inc., Woodinville, USA).
Classification was accomplished using the kNN approach. Leave-one-out (LOO) cross-validation was applied to obtain a first impression of the classification results. However, for “real-life” applications a classification with a training and test-set is more realistic. Therefore, a training and a test-set with approximately the same number of samples in each set (50:50) was built and prediction of those test data in the training data space was carried out. Subsequently, the training and test-set were exchanged and classification was repeated. The results from both runs were averaged. Error estimates were obtained from half the difference between the two results. The optimum neighbourhood parameters k were determined by repeating classification runs with different values of k. Those predictions with the lowest number of misclassifications gave the optimum neighbourhood parameter. kNN classification was performed using Pirouette 2.70 (Infometrix Inc., Woodinville, USA).
The complete dataset containing controls and samples taken at time points of significant metabonomic effect amounted to 2844 samples (2203 controls and predose samples, 641 samples postdose). As the controls were overweighted, 9 out of 10 control samples were randomly excluded, resulting in a dataset comprising 210 control urine samples, 328 samples from rats administered with a liver toxin, 145 samples from kidney toxin-treated rats and 168 samples from animals treated with other toxins or manipulations. Reduction of the data to include 48 h time points only resulted in 50 controls and 87, 50 and 60 urine samples after liver, kidney or other treatments, respectively.
PCA of the averaged spectra at each time point gave a clear overview of the treatment- and time-related metabonomic effects as observed by NMR spectroscopy of the urine (Fig. 2 ). Separation of these data points can be attributed to alterations in NMR signals of endogenous urinary metabolites as seen in the loadings plot. Urines from streptozotocin-treated animals revealed a urinary metabolic profile distinct from all other treatment groups, mainly due to elevated glucose signals (δ = 3.4–3.88). Furthermore, the treatment with kidney toxins HCBD (K2) and mercury chloride (K4) resulted in common metabonomic effects, which were expected because both toxins cause tubular necrosis. Treatments resulting in a periportal liver lesion, such as the two groups of hydrazine-treated rats (L1, L2), are described by an increase in the scores for PC3 (due to an increase in e.g. taurine at δ = 3.28 and 2-aminoadipic acid at δ = 2.24, 1.64). Partial hepatectomy (L9), where entire liver lobes were removed, showed a similar increase in PC3, but still this group could be differentiated from L1 and L2. Other liver toxin groups, such as ANIT (L3, biliary, necrosis) and BHT (L5, centrilobular necrosis), showed opposite metabolic effects resulting in a decrease in PC3, and were well separated from hydrazine-induced liver toxicity.
Fig. 3 shows the best separation between controls (C), liver (L) and kidney (K) toxins using PLS-DA. It reveals that some samples from the kidney treatment group (K1, K3, K5) overlapped with samples from the liver treatment group. This most likely led to some misclassifications in the subsequent kNN classification runs. Many of the urines from the liver group clustered together and only L1 and L2 were significantly separated from the bulk of liver toxins. Late time points from studies L5 (BHT) and L9 (partial hepatectomy) overlapped with the control samples, suggesting that major effects in these studies were seen at early time points and that the urinary excretion profile at these later time points had returned close to normal. Finally, L1, L2 and K2, K4 showed the best separation between liver and kidney toxins as well as from control samples.
Hierarchical cluster analysis of the averaged spectra at each time point identified four main clusters (at a similarity level of approximately 0.7) (Fig. 4 ). Three of these clusters were composed of those studies showing the largest metabonomic effects: streptozotocin (O2) in one cluster, HCBD (K2) and mercury chloride (K4) in the second, and the two hydrazine studies (L1, L2) in the third cluster. This separation agreed well with the principal component analysis results.
The remaining cluster was separated into four distinct subgroups. The first subgroup contained samples from liver (L3, L5, L7) and kidney (K1, K3) dose groups. This especially highlights the aspect that some of the samples from the kidney toxin studies showed borderline-character between the classes liver and kidney, which was confirmed by the PLS-DA of control, liver and kidney samples (Fig. 3). One example is adriamycin (K1) which was assigned to the group of kidney toxins prior to analysis due to its predominant kidney toxicity, although slight histopathological liver effects were observed (decreased glycogen content). 2-Chloroethanamine (K3) was also found to show slight signs of liver toxicity (hepatitis, vacuolar degeneration and decreased glycogen). These findings indicate that the metabonomic analysis of urinary NMR data is sensitive to identifying toxin group similarities without detailed a priori knowledge of the histopathological characterisation. The second subgroup consisted entirely of samples from partially hepatectomised rats and indicated that although these samples showed some comparable effects to those of the hydrazine treatment group (Fig. 2), differences between the two were visible by HCA. The third sub-cluster consisted of predominantly liver treatment groups and two other studies (O3: chloroform, O5: food restriction). Chloroform induces both liver and kidney toxicity, while the food restriction study is likely to effect liver metabolism by glycogenolysis. The fourth subgroup was made up of mainly controls and control-like samples, e.g. late time points from treatment studies (K5, L5, L9). This emphasises the difference in time-response of animals to different toxins, i.e. onset and recovery. Those samples taken at a late time point from a study with an early recovery were more likely to show an excretion profile similar to control samples. Clustering of insulin (O1) into this subgroup indicates that the variance in the control cluster is larger than the subtle effects observed in the 8 h samples from insulin dosed animals. Overall, the analysis gives an asymmetric clustering structure with a strong tail. We attribute this appearance to the fact that many time points from several studies show a small effect, whereas fewer time points show stronger effects. For example, the first three clusters (studies O2, K2 & K4, L1 & L2) comprising 23 time points show the most prominent changes. Conversely, the fourth cluster, containing studies with weaker effects, is composed of 80 time points. This leads to ‘overweighting’ towards studies with smaller effects or even samples with high similarity to controls (mostly later time points in studies).
HCA as an unsupervised technique not only identified clear organ-toxicity specific differences but also showed similarities between samples. The overlap between treatment groups helped to explain the misclassifications in the subsequent kNN analysis.
The most important goal in in vivo toxicity assessment is the determination of whether a drug is toxic, and subsequently which organ is affected. PCA, PLS-DA and especially HCA gave an impression of how well the different groups, defined by target organ, may be separated. Using the samples from the 19 studies taken at 48 h p.d., where the time point of maximum metabonomic effect was apparent in many of the studies, the classification into the three classes controls, liver and kidney resulted in greater than 85% correct prediction of the true class (Table 2 ) in LOO cross-validation using kNN. The best classification was achieved for the controls and liver treatment groups. Introducing a fourth class (other) led to a slight drop in correct classification of the control and liver group suggesting some misclassification into the other group. A total of 85% of the other group itself was predicted into the true class. As expected, it was more likely for those studies where the major metabonomic effect was seen at a different time point than 48 h to be misclassified as controls. This was true for the unilateral nephrectomy (K5) and the insulin treatment (O1) groups where major effects were only observed in the 8 h samples. Further reasons for misclassification were revealed in the HCA analysis, where studies from the other group (O3, O5) had close similarities to the liver group. In general, the use of training–test-set (50:50) classification resulted in a slight reduction of 2–8% in the number of correct classification results compared to leave-one-out cross-validation, but provided a more robust model.
The importance of using the whole time-related urinary profile becomes obvious from the classification results obtained using all time points significantly different from controls (Table 3 ). Here, the classification of the samples resulted in a more even prediction success across the three groups (controls, liver, and kidney). LOO cross-validation resulted in greater than 90% true-class prediction. After introducing the other class, the correct prediction of the different classes in LOO cross-validation varied between 88 and 95% (training–test-set classification: 85–91%).
With the exception of the liver group, all other classes showed an improvement from the use of more than one time point. The other group benefited from including the 8 h time point as this was important for the insulin study. In addition, the correct prediction of samples belonging to the kidney class increased due to the inclusion of the 8 h time point in study K5 (unilateral nephrectomy). Liver organ prediction was reduced (Table 4 ) due to the similarity of some of the late time points with control samples (L5, L9, see Fig. 4).
In general, our results for the organ-specific prediction suggest that the heterogeneity within the organ groups due to suborgan specific effects and different mechanisms of toxicity causes overlap between the groups. This will be taken into account while constructing larger databases. The use of a specific control model will ease the identification of important time points in the studies showing an effect compared to controls.
To investigate the next level of structure within the data, classifications were performed using each single toxicological study and the control samples as an individual class. Here, the study-by-study prediction employing all time points significantly different from controls (Table 5 ) was able to predict correctly the true class in 86% of cases using LOO cross-validation (81% for training–test-set classification). Although the datasets analysed here have not been used to explore suborgan toxicity or toxic mechanisms specifically, the fact that each study can be clearly predicted as a separate class strongly suggests that such classification will be possible. We are currently exploring this aspect.
As a severe test, the division into subgroups can be pursued further so that the data is split into 87 classes where each class represents one treatment at one time point, plus one additional class for controls. With this time point-by-time point prediction (Table 5) the overall results for a correct time point prediction were between 64 and 67%, depending on the classification procedure. Fig. 5 illustrates the results from the training–test-set prediction for every individual time point from the different studies. One axis shows the true class, the other axis those time points into which the samples were predicted (‘predicted class’). The strong diagonal demonstrates that many of the samples were classified either into the correct time point of the right study, or into adjacent time points. This means that a sample which was not correctly classified into its time point was however closely predicted and mostly predicted into the right study. Reasons for misclassifications include the overlap between late time points from the treatment groups and control samples, and the similarity between the food restriction groups with 25 and 50% food reduction. As all time points from the studies together with controls amount to 88 classes, one would expect to assign a sample by chance to the correct class with a success rate of 1.1%, well below our success rates.
Success of any prediction system will be determined by the selection of classes or subclasses and the number of samples in these classes. We are well aware that the ratio of samples in the different groups is an important aspect, and therefore we examined the impact of increasing the number of samples in the control group on the organ classification (48 h only). If the number of controls in our dataset was increased by approximately three-fold, the true-class prediction success for controls increased by 3% but this led to a decrease in classification success of 7% for the other group using LOO cross-validation. As this variance is due to strong overweighting, we expect our original dataset to be less affected.
Our results show that the metabonomic approach of toxin prediction is highly competitive compared to other approaches using, e.g. genomic or proteomic information . Metabonomics has already proven useful in the description of liver and kidney toxicity using PCA and SIMCA . One application used probabilistic neural networks (PNNs) to predict toxin-affected organs in two different rat strains at an overall success rate of 94% . For each strain, samples were predicted into five classes (liver, kidney, liver & kidney, mitochondrial toxins and controls). The use of more diverse classes, such as multiple-organ toxicity (liver & kidney), should lead to improved classification results, however, kidney toxicity in Sprague-Dawley rats was correctly predicted with 7% lower success rate using PNNs than with our approach using four distinct classes. Our dataset also contained a higher number of samples per class which strengthens the confidence in our results. In addition, the authors used SIMCA and multi-layer perceptrons for comparison with PNNs. However, both techniques proved to be less successful. An analytical method called CLassification Of Unknowns by Density Superposition (CLOUDS) was developed within the COMET project and is also presented in these proceedings . We have demonstrated that this non-neural technique, derived from PNNs, gave similar results within the error range compared to the robust and well-known kNN method when applied to the same data set. This emphasises the reliability of both approaches. Furthermore, CLOUDS can be tailored to complex tasks using diagnostics such as confidence and uniqueness which gives further flexibility to its use in multiparametric analysis.
The application of proteomic techniques as yet has played a minor role in the prediction of toxicity despite its wider use in mechanistic toxicology , however the genomic approach of using gene expression data from tissues for predicting toxicity (toxicogenomics) is becoming increasingly popular . In such studies messenger RNA information is extracted from liver tissue samples after treatment with different liver toxins. The gene expression data from 15 hepatotoxins were examined with clustering techniques revealing several similarities between different groups of the toxins and their correlation to histopathology and clinical chemistry findings . A prediction accuracy of 92% for the prediction of two toxin classes (enzyme inducers and peroxisome proliferators) was achieved using an approach with linear discriminant analysis and genetic algorithms/kNN . We have shown that the metabonomic approach can be applied to more complex classification tasks. So far, the gene expression classifications are very much focused on liver toxicity and liver subgroup-toxicity . And, although gene expression analysis has shown reasonable results in the examination of liver toxins, it is very labour-intensive requiring lengthy tissue preparation and PCR amplification and the cost of the micro-arrays is also considerable. These reasons often reduce the applicability of the technique to only single time points in the course of a toxicological study. The NMR analysis of urine samples meanwhile is easy and quick to perform which allows an immediate analysis at every important stage within the time course of a study. It is non-destructive and gives access to a variety of metabolic pathways—a big advantage for high-throughput screening for drug toxicity.
As part of a larger effort to construct a comprehensive database of urinary metabonomic data from toxicological investigations, these preliminary results have underlined the potential of our approach for the prediction of drug toxicity. Data were employed from animal studies showing metabonomic effects due to toxin administration, surgical procedures (partial hepatectomy, unilateral nephrectomy) and other treatments (food restriction, water deprivation). It was shown that chemometric methods such as PCA, PLS-DA and HCA are important tools in the exploration and visualisation of toxicological effects in the rat. These techniques improve the understanding of the structure of metabonomic databases regarding toxin-, organ-, suborgan- and time-specificity. Within the COMET project, methods of chemometric modelling of NMR-derived, metabonomic data from animal studies are being developed for the prediction of drug toxicity. Our results, employing kNN classification suggested a good predictability of liver and kidney toxicity and other effects. More comprehensive classification based on suborgan-sites or mechanisms of toxicity is currently being explored.